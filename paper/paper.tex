\documentclass[11pt]{article}
%\documentclass[11pt,draft]{article}   % uncomment this and comment out the above line for *fast* typesetting (no images)
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\newcommand{\mycaption}[1]{\begin{quote}{\bf Figure: } \large #1\end{quote}}



%%%% Theoremstyles
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{hypothesis}[theorem]{Hypothesis}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{question}[theorem]{Question}
\newtheorem{project}[theorem]{Project}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{alg}[theorem]{Algorithm}
\newtheorem{openproblem}[theorem]{Open Problem}

%\theoremstyle{remark}
\newtheorem{goal}[theorem]{Goal}
\newtheorem{aside}[theorem]{Aside}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remarks}[theorem]{Remarks}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{suggestion}[theorem]{Suggestion}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}


\textwidth = 6.5 in
\textheight = 9 in
\oddsidemargin = 0.0 in
\evensidemargin = 0.0 in
\topmargin = 0.0 in
\headheight = 0.0 in
\headsep = 0.0 in
\parskip = 0.2in
\parindent = 0.0in


\def\GL{\mathrm{GL}}
\def\PGL{\mathrm{PGL}}
\def\PSL{\mathrm{PSL}}
\def\S{\mathcal{S}}
\def\s{S_{\rm Riemann}(X)}
\def\Z{\bf{Z}}
\def\Q{\bf{Q}}
\def\Gal{\mathrm{Gal}}
\def\Hom{\mathrm{Hom}}
\def\Ind{\mathrm{Ind}}
\def\End{\mathrm{End}}
\def\Aut{\mathrm{Aut}}
\def\loc{\mathrm{loc}}
\def\glob{\mathrm{glob}}
\def\Kbar{{\bar K}}
\def\D{{\mathcal D}}
\def\z{{\mathcal Z}}
\def\l{{\Lambda}}
\def\L{{\mathcal L}}
\def\p{{\mathcal P}}
\def\R{{\bf R}}
\def\G{{\mathcal G}}
\def\W{{\mathcal W}}
\def\H{{\mathcal H}}
\def\O{{\mathcal O}}


\title{How explicit is the Explicit Formula?}
%{Arithmetic statistics of central zeroes  of $L$-functions of the symmetric $n$-th powers of a given automorphic form}
\author{Barry Mazur and William Stein}
\begin{document}
\maketitle


%\hskip20pt ({\it Notes for our  20+20 minute talk at the  AMS Special Session on Arithmetic Statistics in San Diego, January 2013}
\vskip10pt
\centerline{\bf Preface}
\vskip10pt

The  term `Explicit Formula' as in our title refers to the genre of formula that expresses {\it arithmetically interesting quantities} in terms of the zeroes of  a related zeta-function or $L$-function.  The first such formula appears towards the end of Bernhard Riemann's short and great paper  ``\"{U}ber die Anzahl der Primzahlen unter einer
gegebenen Gr\"{o}sse," published in the
Monatsberichte der Berliner Akademie,
November 1859.  Subsequently there have been many versions of Explicit Formulas, one such notable variant  proved by Hans von  Mangoldt, in his 1895 article  "Zu Riemann's Abhandlung ``\"{U}ber die Anzahl der Primzahlen unter einer gegebenen Gr\"{o}sse"", Journal f\"{u}r die reine und angewandte Mathematik.  We devote this expository  article in honor of Riemann to a discussion of formulas of this type. Our main aim is to formulate some open questions related to the application of the Explicit Formula to the arithmetic of elliptic curves.

  The {\it arithmetically interesting quantity} that appears in most of the `Explicit Formulas' of analytic number theory is often  a partial sum $F(X)\cdot\sum_{p<X}G(p)$ of locally defined quantities $G(p)$ attached to prime numbers $p$, summed to up to some cutoff value, $p<X$  (and normalized for convenience by an elementary factor $F(X)$). The formula expresses this function of the variable $X$, $F(X)\cdot\sum_{p<X}G(p)$, as a {\it dominant term}, plus an easily controlled error term, plus an interesting third term that might be called the {\it oscillatory term} that, in most cases, is only conjecturally controllable.

  Usually the {\it dominant term} is computed by knowing the order of specific zeroes `at central points' of relevant (global) $L$-functions, the `easy error term' is related to the so-called {\it trivial zeroes} of those relevant $L$-functions, while the {\it oscillatory term} is  a specific function of ($X$, and of) the infinitely many remaining nontrivial zeroes of those $L$-functions.


 There are theoretical and computational challenges in working out the  numerical contributions of these terms of the formula in concrete cases.
 %We have no new results here, but our aim in this half hour plus ten minutes of discussion, is to offer numerical {\it visualizations} of the analytic formula in various interesting cases to advertise the need for some  precise conjectures and computational projects regarding this problem and to recount some recent work.\ More for the future will be  our plans for a web-accessible resource: a repository of some of the numerics for the cases related to elliptic curves that interest us.

   In this expository article, we will examine the analytic formula in various interesting cases to advertise the need for some  precise conjectures and computational projects regarding this problem and to recount some recent work.\  We focus on applications to elliptic curves, but we take this only as a basic (important) example of a fuller story for general motives.  We have  future plans for a web-accessible resource: a repository of some of the numerics for the cases related to elliptic curves that interest us.

  Specifically we will  focus on {\it issues of bias}  following the classical ``Explicit Formula,'' and the work of:
Sarnak, \ Granville,\  Rubenstein,\, Martin-Watkins,\ Fiorilli,\ Bober,\ Conrey-Snaith, and others.
 The example-problem we consider is related to the question---given an elliptic curve over the rational numbers and letting  $p$ range through prime numbers---of how often  $p+1$ is an {\it over-count} or an {\it under-count} for the number of rational points on the curve modulo $p$? The rough answer is 50/50, but there can be a `bias' similar to the classical Chebyshev bias  \cite{R-S}. For such finer statistics one resorts to `Explicit Formulas.'  Here, computation can even outstrip theory in that people have algorithms to make such computations whether or not the holomorphicity of the $L$-functions in question have been proved. Computations have depended on the work of many people.


 We have used this text to provide material for {\it unusually short lectures}. %Specifically, the notes were initially written for each of our 20 minute lectures at the San Diego Conference, as we have already mentioned, but also
 E.g., one of us replayed it all{\footnote{ Well, not quite all$\dots$}} in a 6 minute and 40 second lecture at Harvard. We say this to make it clear that this article is meant to be  somewhat light reading; it contains no new results, as we have mentioned, and no proofs of anything. But we feel that the issues here are a good source of student projects, and that our text might be  a companion to any reader of the beautiful expository articles on classical Chebyshev bias, such as \cite{R-S}, or on the biases we discuss, as in \cite{S}.

\hskip20pt{\small{\tableofcontents}}

\section{Brief Introduction}
 One of us (B.M.) having recently taught the classical {\it Explicit Formula} in a standard graduate course in analytic number theory, and having proved that eponymous formula, garnished---as it usually is--- by a number of so-called ``effective constants," $c_1, c_2,$ etc., felt  that, for some applications, this lettered effectiveness left us still too far from  the statistical phenomena behind the formula. To get a closer bead on things, one would do well to work with the numbers behind these   $c_1$'s and $c_2$'s, etc.  It is natural then to see how `actual data'---cutting off the terms of the formula at suitably large values of $X$ given the range of currently feasible computations---compare with the expected results for arbitrarily large $X$.

 Happily, the other of us (W.S.) has produced relevant computations that do exactly that (for applications of the Explicit Formula to certain problems of current interest to both of us).% This, then, is a phenomenological talk, with (at least the beginning of)  a corpus  of graphs that offer some  illustration of the effectiveness---or non-effectiveness---of the explicit formula in the specific instances of interest to us.

 We offer no new theoretical results but use this occasion to mention some interesting recent work and conjectures  (of other people)  that might warrant more such computations and that raise a host of questions, both theoretical and computational.   For example, to do some systematic numerical computations related to an elliptic curve $E$ attached to a newform $f_E$  (along the lines of what has already been done in this paper)  it would be very useful to have a much larger data-set  of the arithmetic function  $$n \mapsto r_E(n)$$
 where $r_E(n)$ is the order of vanishing of the $L$-function of the automorphic forms $symm^nf_E$ for odd values of $n$.  Regarding this arithmetic function, aside from having control of the parity of   $r_E(n)$  (e.g., see \cite{DMW}))  hardly anything else is known. Nor do we (at least, the authors of this paper)  yet have enough experience---when $E$ has no complex multiplication---even to formulate a proper conjecture.

 We might also mention that when making these numerical experiments one seems to be in a situation  that is not entirely dissimilar from the type of slightly annoying mismatch between conjecture and data that one encounters in more traditional studies of Mordell-Weil statistics  that was the subject of the survey article B-M-S-W.  But this may be unavoidable, given that even  the so-called  `easy error term' in the explicit formula will tend to converge  only $O(1/\log X)$ fast.

 We should say at the outset that for simplicity, and sometimes for necessity, we'll be assuming GRH throughout---without any further mention. In fact, at times we'll also be assuming ({\it with} explicit warning) some further conjectures.


 \section{A qualitative look at the Explicit Formula}
 As mentioned in the Preface, here is the shape of the explicit formula, given in even more qualitative vocabulary:

{\Large $${\rm{\it Sum\ of\ local\ data\  }}  \ = \  {\rm{\it Global\ data}}\ +\  {\rm{\it  Easy\ error\ term}}\ +\  {\rm{\it  Oscillatory\ term}}.$$ }

Before getting started, some general comments. We will be dealing with examples where each of these terms are given as functions of $X$, a cutoff value, where

\begin{itemize}\item We want the term on the LHS,   the {``{\it Sum\ of\ local\ data} cut off at $X$"} to be  a finite sum of the form:

  $$\delta(X) \ = \ F(X)\cdot \sum_{p\le X}G(p)$$

  where the rules of the game (in this paper) are as follows:

  \begin{itemize} \item We require the value $G(p)$ to be determined by only {\it local }considerations at the prime $p$.
The simplest example of such a {\it Sum\ of\ local\ data}  is given by taking $F(X)$ to be the constant $1$, and  $G(p)$ to be  $1$ for all $p$, giving us the classical $\pi(X):=\sum_{p\le X}1$. \item The normalizing factors $F(X)$ will be elementary smooth functions of the cutoff $X$. We sometimes choose this normalizing factor so that the  resulting  $\delta(X)$ has (conjecturally) finite mean.\end{itemize}

We will be concentrating on  {\it sums\ of\ local\ data}  attached to elliptic curves over ${\Q}$,   $$\delta_E(X):=F(X)\sum_{p\le X}g_E(p)$$ where the weighting function $$p \mapsto g_E(p)$$   is a function of $a_E(p)$, the $p$-th Fourier coefficient of the eigenform of weight two parametrizing the elliptic curve.

  We will specifically be interested in  issues of bias. This is what we mean: thanks to the recent resolution of the Sato-Tate Conjecture in this context, one knows that---roughly---half the Fourier coefficients  $a_E(p)$ are positive and half negative.  Indeed, the numbers of positive values and negative values look very close:
\vskip20pt

\begin{center}
\begin{tabular} {r | c | c | c | r}\hline
Curve & Rank & Negative $a_E(p)$ for $p<10^9$ & Positive $a_E(p)$ for $p<10^9$ & Difference\\ \hline\hline
11a    & 0      & 25422268       & 25423101     &   -833 \\ \hline
14a    & 0      & 25422229       & 25421074     &   1155 \\ \hline
128b   & 0      & 25420641       & 25425608     &   -4967 \\ \hline
816b   & 0      & 25424848       & 25421229     &   3619 \\ \hline
2379b  & 0      & 25417900       & 25427007     &   -9107 \\ \hline
5423a  & 0      & 25420479       & 25425242     &   -4763 \\ \hline
29862s & 0      & 25420525       & 25425197     &   -4672 \\ \hline
37a    & 1      & 25423396       & 25422448     &   948 \\ \hline
43a    & 1      & 25421536       & 25424196     &   -2660 \\ \hline
160a   & 1      & 25424446       & 25421488     &   2958 \\ \hline
192a   & 1      & 25418843       & 25426859     &   -8016 \\ \hline
2340i  & 1      & 25425512       & 25419660     &   5852 \\ \hline
10336d & 1      & 25421245       & 25423628     &   -2383 \\ \hline
389a   & 2      & 25427014       & 25418738     &   8276 \\ \hline
433a   & 2      & 25425902       & 25419896     &   6006 \\ \hline
2432d  & 2      & 25423818       & 25421900     &   1918 \\ \hline
3776h  & 2      & 25422350       & 25422750     &   -400 \\ \hline
5077a  & 3      & 25426985       & 25418831     &   8154 \\ \hline
11197a & 3      & 25429098       & 25416702     &   12396 \\ \hline
\end{tabular}
\end{center}

\vskip20pt
  To study, then, the weighted sums that directly reflect finer statistical issues related to this symmetric distribution, we will be concentrating on weighting functions $p \mapsto g_E(p)$ that have the property that \begin{itemize} \item for all primes $p$, $g_E(p)$ is an {\it odd} function of the value  $a_E(p)$, and \item the {\it sum\ of\ local\ data}  $$\delta_E(X):=\sum_{p\le X}g_E(p)$$ has---or can be convincingly conjectured to have---a finite mean{\footnote{ See Section {\ref{mean}} below}} relative to multiplicative measure $dX/X$.\end{itemize}  In such a context  the mean of $\delta_E(X)$ can be interpreted as a {\it bias}!


 For example, to consider  the problem highlighted in our {\it Preface} (above) form  the `sum of local data'
  $${\frac{\log X}{{\sqrt X}}}\sum_{p\le X}\gamma_E(p)$$  where $\gamma_E(p)=0$ if $p$ is a bad or supersingular prime for $E$ and is otherwise is $+1$ if $E$ has less that $p+1$ rational points over ${\bf F}_p$; and $\gamma_E(p) = -1$ if more.  Then this sum, which will be denoted $\Delta_E(X)$ below, measures exactly the difference between over-count and under-count, as formulated in the {\it Preface}.\vskip10pt
\section{ The three terms on the RHS  of these Explicit Formulas}
  \vskip10pt
\item The first  term on the RHS of our Explicit Formulas, i.e. the term we labeled ${\rm{\it Global\ data}}$, is a constant independent of $X$   determined by the certain `central'  (real)  zeros, or the poles, of the relevant $L$-function or collection of $L$-functions. The   collection of $L$-functions {\it relevant} to the problem highlighted in our {\it Preface} consists of  the $L$ functions attached to {\it all}  the {\it odd} symmetric powers of the newform $f_E$, and the Global data is a function of the multiplicity of the zeroes of these $L$-functions at their central (real) points, where central refers to the functional equation that they enjoy.

Often, and under GRH, these {\it real, central} zeroes of the relevant $L$-functions will have---conjecturally---a clean {\it global arithmetic interpretation} (e.g., via BSD and its  variants) so that's why we call  that term simply  ``{\rm{\it Global\ data}}."  In the problems we will be discussing this ``global data" will be showing up as a certain {\it bias} in the arithmetic statistics of elliptic curves that hearkens back to the early work of Birch and Swinnerton-Dyer, but in the context of the vocabulary we will be using, was  first written down by Peter Sarnak; this is in the spirit of the classical Chebyschev bias, and 'prime races;' an `Explicit Formula' account of this classical theory can be found in {\cite{GM}}.
\item Often the
'easy error term' converges (like $O(1/
log X)$) to a value  (perhaps zero) as $X$ tends to infinity.
\item The {\rm{\it  Oscillatory\ term}} is determined by the (infinitely many) complex (``nontrivial") zeroes. It is usually  an infinite sum, where  (after appropriate conjectures) the summands are of the form  $X^{i\gamma}/f(\gamma)$ where $\gamma$ runs through the imaginary parts of the complex zeroes of the relevant $L$-functions, and $f(y)$ is some natural function.  Numerically, this oscillatory term will indeed oscillate---as we shall amply see---but often one  is tempted to, at the very least, conjecture some control over this wild card.  In actual computations we are surprised by  how small it is.\end{itemize}


\vskip20pt
 \centerline{ \Large{ Part I: Setting up}}
  \vskip30pt
 \section{Bias Questions} Let $E$ be an elliptic curve over ${\Q}$  with no complex multiplication, associated to a newform whose $p$-th Fourier coefficient for $p$ a prime is denoted, as usual, $a_E(p)$. Given the recent work on Sato-Tate, the probability distribution determined by  the normalized values   ${\frac{a_E(p)}{2{\sqrt {p}}}}$  is known to be symmetric about the origin for a large class of such elliptic curves. To repeat our starting question:

 % It is natural, then, to ask for more detailed description of this  data; for example, to raise what one might call {\it bias questions} that {\it race one side of that probability distribution against the other}. A typical such question is the one cited in our {\it Abstract}:
\begin{quote} Given an elliptic curve over the rational numbers, and letting  $p$ range through prime numbers, how often is $p+1$  an over-count or an under-count for the number of rational points on the curve modulo $p$?  \end{quote}



  As mentioned above,  for a large class of elliptic curves, as a consequence of recent work on the Sato-Tate Conjecture, the answer is grossly  {\it equally often} in the sense that, putting $$N_E(p)=1+p-a_E(p):=\ {\rm the \ number\ of \ rational\ points \ on\ } E\ {\rm over}\  {\bf F}_p,$$

  the ratio

 $${\frac{\#\{p < X \ | \ N_E(p) < p+1 \}} {\#\{p > X \ | \ N_E(p) > p+1 \}}}\ =\ {\frac{\#\{p < X \ | \ a_E(p) > 0 \}} {\#\{p > X \ | \ a_E(p) < 0 \}}}$$

 tends to $1$ as $X$ goes to infinity, and we will be considering more delicate {\it bias questions} by examining a variety of ``rough," and ``smooth," ways of measuring  the preponderance of positive---or of negative---$a_E(p)$'s. We wish to actually make such measurements, and take a look at their graphs.


 This type of question, of course, bears on Birch's and  Swinnerton-Dyer's initial ``hunch" that the  statistical preponderance of solutions modulo $p$ of an elliptic curve is a predictor of whether or not the elliptic curve has infinitely many rational points.
 \section{ The LHS of our Explicit Formulas}
  To give some ad hoc terms for variant partial sums of {\it Local Arithmetic Data} that measure such preponderances,  let us refer to\begin{itemize}\item   (the slightly doctored version of) the straight difference,
 $${\Delta}_E(X):=  {\frac{\log\ X}{\sqrt X}}\big(\#\{ p < X\ | \ a_E(p) > 0\}\ - \ \#\{ p < X\ | \  a_E(p) < 0\}\big),$$  as  the {\bf raw data,} \item and to
 $${\mathcal D}_E(X):= {\frac{\log\ X}{\sqrt X}}\sum_{p \le X}{\frac{a_E(p)}{\sqrt p}}$$ as the {\bf medium-rare data}, and \item
  $${D}_E(X):= {\frac{1}{\log\ X}}\sum_{p \le X}{\frac{a_E(p)\log p}{ p}}$$  as the {\bf well-done data}.
  \end{itemize}
 \subsection{The statistical distinctions between the three formats}\label{statdist}
   Not to build up too much suspense here, the reason for selecting these three formats for the ``Local data"  and for the specific normalizations chosen (i.e., the factor $ {\frac{\log\ X}{\sqrt X}}$ occurring in the first two, and the factor  ${\frac{1}{\log\ X}}$ in the third)  is that they each are amenable to analysis via ``an" {\it Explicit Formula}
   $$(*)\  \  \  \  {\rm{\it Sum\ of\ local\ data\  }}  \ = \  {\rm{\it Global\ data}}\ + \  {\rm{\it  Easy\ error\ term}}\ + \  {\rm{\it  Oscillatory\ term}}$$
 and such that if (GRH plus)  certain interesting conjectures hold---then  all three  Sums of Local Data, $${\Delta}_E(X), \ {\mathcal D}_E(X), \ {\rm and} \ D_E(X)$$ will have finite {\it means}  (relative to the measure $dX/X$ on ${\bf R}^+$), their `means' being equal to the term  {\rm{\it Global\ data}} in their corresponding Explicit Formula;  and furthermore, what distinguishes these three formats is that conjecturally{\footnote{ as described in a letter of Sarnak; see subsection{\ref{SL}} below.}}---
   \begin{itemize}
   \item the raw data will have {\it infinite} variance,
   \item the medium-rare data will have {\it finite variance}, and
   \item the well-done data will actually achieve its mean as a limiting value.
   \end{itemize}

   For a picture gallery of graphs of these Sums of Local Data, see Part III below. For a more extensive data base of such pictures, see ****

  \section{ The RHS of our Explicit Formulas}
   Here are some brief comments on each of the three  `terms' (i.e., {\it Global data}, {\it  Easy error term}, and {\it  Oscillatory term})  on the RHS of the Explicit  Formula for the well-done variant (see above) for the elliptic curve $E$:

   $${D}_E(X):= {\frac{1}{\log\ X}}\sum_{p \le X}{\frac{a_E(p)\log p}{ p}}\hskip30pt = \hskip30pt \rho_E\ \ \  + \  \ \ \epsilon_{E}(X)\ \ \  + \ \ \ {\frac{1}{\log X}}S_E(X).$$ For the definition of $S_E(X)$, see section \ref{osc} below.
 \subsection {The `{\it Global Data}' or---conjecturally-- the {\it `Mean'}}\label{mean}
   Recall that if   $X \mapsto \delta(X)$ is a (continuous) function of a real variable,  to say that $\delta(X)$ {\bf possesses a limiting distribution $\mu_\delta$ with respect to the multiplicative measure $dx/x$} means that  for continuous bounded functions $f$ on ${\bf R}$ we have:
\begin{equation*}
\lim_{X \to {\infty}}\ {\frac{1}{\log X}}\int_0^Xf(\delta(x))dx/x \ = \ \int_{\bf R}f(x)d\mu_\delta(x).
\end{equation*}

\bigskip

    Recall that the {\bf mean} of the function $\delta(X)$ (relative to $dX/X$) is defined by the limit  $${\mathcal E}(\delta):= \lim_{X \to {\infty}}{\frac{1}{\log X}}\int_0^X\delta(x)dx/x \ = \ \int_{\bf R}d\mu_\delta(x).$$

     The depressing thing here is that if you take a function $\delta(X)$ that is anything you want up to $X = 4,000,000$ and equal to $5$ for $X>  4,000,000$ then the mean of $\delta$ is equal to $5$, so what in  the world can it mean{\footnote{ poor pun intended}} to compute data up to $4,000,000$? But we press on.

   The standard conjectures for the terms in our three formats above tell us that---in all three of our examples---the values of {\it means} are given by the `global data.' In particular, for the well-done  variant, the mean is conjectured to be $\rho_E$.  More specifically:

    \begin{itemize}
   \item {\bf The well-done data:} the  mean is (conjecturally) $\rho_E= -r_E$ where $r_E$ is the {\it analytic rank} of $E$.
    \item {\bf The medium-rare data:} the  mean is  (conjecturally)  $1-2r_E$ and
      \item {\bf The raw data:} the  mean is  (conjecturally) \begin{equation*}
{\frac{2}{\pi}}- {\frac{16}{3\pi}}r_E \ \ \ + \ \ \  {\frac{4}{\pi}} \sum_{k=1}^{\infty}  (-1)^{k+1}\big[{\frac{1}{2k+1}} + {\frac{1}{2k+3}}\big]r_E({2k+1}).
\end{equation*} where $$r_E(n):= \ r_{f_E}(n)\ = \ {\rm the\ order\ of\ vanishing\ of\ }L(symm^nf_E, s)\ {\rm at}\ s=1/2,$$ with $f_E:=$ the newform of weight two corresponding to the elliptic curve $E$; and where we have normalized things as the analysts love to do, so that $s=1/2$ is the central point. {\bf NOTE:} For a discussion of the numerics of the values $r_E({2k+1})$, see Section {\ref{highord}} below.
   \end{itemize}
% \noindent which leads us to our initial question: \begin{quote} What is the behavior of the function  $$n \mapsto r_ f(n)$$ for fixed $f$ and varying $n$? \end{quote}
  %
  \subsection{The  `{\it Easy\ error term}'}

   Let us leave any analysis of this term, $\epsilon_E(X)$, as an interesting  student-project.
 \begin{project} Work out theoretically in general, and computationally for a few specific elliptic  curves, the nature of the easy error term  $\epsilon_E(X)  = O(1/\log X)$ and estimate the explicit constants.\end{project}
 % This term indeed converges to zero, and  is given by some `elementary' smooth bounded function of $X$ that is $O( {\frac{1}{\log X}})$.

 % \vskip20pt
 % \centerline{\bf William 1}
  %{\it We should have a good discussion of this, since everything in it is---I think---pretty computable and should simply be---say for the the `well-done data,'--- of the form\vskip20pt  $${\frac{{\rm some\ elementary\ bounded\ function\ o f\ } X}{\log X}}.$$\vskip20pt  To clarify this `easy error term,' perhaps for a general weighted bias, might be a very good project for the graduate student who worked out the constant term in the classical Explicit Formula. }

 \section{The `{\it Oscillatory term}'}\label{osc}
  Although this oscillatory sum is similar for all three formats, here let us concentrate on this term as it appears in the Explicit Formula for the `well-done data,'  $D_E(X)$. We write it as  ${\frac{1}{\log X}}S(X)$ where $S(X)=S_E(X)$ is the limit, as $T$ tends to infinity, of the trigonometric series:

  $$S_E(X,T) = \sum_{0<|\gamma| \le T}{\frac{X^{i\gamma}}{i\gamma}},$$

  where the sum is over the imaginary parts of the complex zeroes of  $L(f_E, s)\ {\rm at}\ s=1/2.$   It is a consequence of the explicit formula that $S_E(X)$ does (conditionally) converge and it has been tentatively suggested  (e.g., see [{\cite{S}}]) that

  \begin{conjecture}  $ S_E(X)\ \  {\stackrel{?}{=}}\ \  o(\log X).$\end{conjecture}   The analogous oscillatory term for the classical Riemann zeta function  has an extensive literature. See, for example \cite{G}, \cite{Fu} and the bibliography there. Here are some pictures to convey a sense of how our $S_E(X,T)$ behaves, at least in the currently computable range which (roughly) allows $T$ to be only as high as  $10^4$.
  \newpage
  \centerline{ $E = 11a$}
 \vskip10pt
  \includegraphics[width=0.9\textwidth]{plots/OSC11.pdf}

  \centerline{ $E = 37a$}
  \includegraphics[width=0.9\textwidth]{plots/OSC37.pdf}
%\vskip20pt
 % \includegraphics[width=1.0\textwidth]{plots/OSC.pdf}
   \vskip20pt
  \centerline{ $E = 389a$}
\vskip20pt
  \includegraphics[width=0.9\textwidth]{plots/OSC389.pdf}

 From these examples, one might imagine that for 'most arguments $X$' the range of actually achieved values of $S_E(X)$  may be even more restricted than Sarnak's suggestion, i.e., $o(\log X)$ as quoted above. That is, even if  the function $X \mapsto S_E(X)$ is in fact unbounded, it might be the case that it spends most of its time having a very restricted upper bound for its values.  To study this, let us consider the distribution of values of $S_E(X,T)$ for any fixed $(X,T)$ with $T$ large.


%%%%
\subsection{Distributions of values }

Let ${\R}_{>0}$ be the multiplicative group of positive real numbers, and ${\R}$ the additive group of reals. For $I \subset {\R}_{>0}$ a Haar measurable set, let $|I|$ denote a Haar measure.  Let ${\S}:{\R}_{>0} \to {\R}$ be a real-valued Lebesgue-integrable function.  Fixing $I \subset {\R}_{>0}$ a subset  of finite measure,  for every measurable subset $J\subset {\R}$, form the probability measure on ${\R}$
$$J\mapsto \mu_{{\S},I}(J): = {\frac{|I\cap {\S}^{-1}(J)|}{|I|}}.$$  So, $\mu_{{\S},I}(J)$ is the {\it probability that the function ${\S}$ achieves a value in the range $J$ over the gamut of arguments in $I$.}   Say that ${\S}$ has a {\bf normal distribution of values} if, for $X > 0$ setting $I_X= (0,X]$, the limit  $$\mu_{{\S}}:= \lim_{X \to \infty}\mu_{{\S},I_X}$$ exists. These  definitions are particularly relevant to the oscillatory terms ${\S}(X):= S_E(X)$ that we are currently studying. The data seems to indicate convergence to a limiting distribution (the  mean  value being $0$) with a strikingly small (variance, or equivalently: strikingly small) standard deviation of values.
\vskip20pt
Here, then, are some pictures  of what seems to be data 'converging' to a limiting  distribution $\mu_E$ of the values of the oscillatory terms $S_E(X)$ for a few elliptic curves $E$:
  \vskip10pt
  \centerline{ $E = 11a$}
 \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/bite11.pdf}
    \vskip10pt
  \centerline{ $E = 37a$}
  \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/bite37.pdf}
    \vskip10pt
       The red curve is the normal distribution with mean $0$ and standard deviation given by that of the data.
   \vskip10pt
    {\bf  Note: } Conditional on the conjecture $LI(E)$ (see section \ref{Fi} below) $\mu_E$ exists (see \ref{S}).

     It is interesting  to compare $\mu_E$ to the limiting distributions connected to the bias of nonresidues to residues mod $q$, as in \cite{R-S}. There one has the added feature that these limiting distributions themselves tend to the normal distribution as the modulus q tends to infinity.
   % \includegraphics[width=0.9\textwidth]{plots/bite389.pdf}
 %\vskip30pt
  \centerline{ $E = 389a$}
  \vskip10pt
\hskip100pt  \includegraphics[width=0.6\textwidth]{plots/bite389.pdf}

 %If so, we define the {\bf  mean  value of ${\S}$} and the {\bf standard deviation (of values) of ${\S}$} to be the mean and standard deviation (respectively) of the limiting normal distribution $\mu_{{\S}}$.

   {\bf Definition:}  The {\bf bite}, $\beta_E$, of the oscillatory term $S_E(X)$ is the standard deviation of the   distribution $\mu_E$ of values of $S_E(X)$.

    {\bf  Note: } Conditional, again,  on standard conjectures  one can show that the bite of $\mu_E$  grows like $c\cdot \log {\rm cond}(E)$ for some constant $c$; see \ref{S}. it is tempting to think of rescaling $\mu_E$ to have a convergent `rescaled bite' as ${\rm cond}(E)$ tends to infinity, and to ask whether (after such a rescaling) these distributions converge to the normal distribution.

 Here are a few examples comparing the bite to the conductor. We also compare this data this to the quotient $$\lambda_E:={\frac{ \log {\rm cond}(E)}{\beta_E}},$$ and to the Mordell-Weil rank $r_E$:



  \begin{tabular}{llllllllll}
  $E$   &\ & 11a & 37a & 389a & 431b1 & 443c1 & 5002c1 & 5021a1 & 5077a\\
\  &\ &\  &\  &\  &\ &\ &\ &\ &\ \\
  $\beta_E \approx $  &\ & 0.5 & 0.61 & 0.89 & 1.38 & 1.40 & 1.57 & 1.94 & 1.19\\
  $\lambda_E  \approx$  &\ & 4.8 & 5.9 & 6.7 & 4.3 & 4.4 & 5.4 & 4.4 & 7.1\\
  $r_E =$   &\ & 0 & 1 & 2 & 0 & 0 & 0 & 0 & 3 \end{tabular}
\vskip10pt
\begin{project} Continue the computations above to be able to get good approximations to the absolute constant $c$. \end{project}

  But there is a finer structure to the behavior of the oscillatory term. For that, one must zoom in and focus attention to the values of $X$ that are close to powers of prime numbers. We will now do that.


 \subsection{ The Gibbs Phenomenon in the oscillatory term} The Explicit Formula for $D_E(X)$ tells us that we might well expect discontinuities of the function $S_E(X)$ for prime number values of $X$. The analogous question has been  examined in the case of the classical Riemann zeta-function.  Here is a brief resum{\'e} of information one finds about this in the literature. Let $$S_{\rm Riemann}(X): = \sum_{|\gamma|<X}X^{i\gamma}/i\gamma,$$ where $\gamma$ ranges through the nontrivial zeroes of $\zeta(s)$, the Riemann zeta-function. This oscillatory term has been  embedded in what one might call a `Lerch spectral zeta function,' defined by the Dirichlet series:

 $$Z_{\rm Riemann}(X,s): =   \sum_{|\gamma|<X}X^{i\gamma}/i\gamma^s,$$ where again $\gamma$ ranges through the nontrivial zeroes of the Riemann zeta function.  For fixed $X\ge 0$ the function $Z_{\rm Riemann}(X,s)$ extends to a meromorphic function of $s$ on the  complex plane, and for $X>0$ it is entire{\footnote{ See \cite{Fu3} for the latter statement, and \cite{Fu1}, \cite{Fu2} for its proof.\vskip10pt}}.  The special case of $Z_{\rm Riemann}(1,s)$  fits into the immense literature regarding `spectral zeta-functions,' that extends to asymptotic
distributions of eigenvalues for oscillating membranes, and  to Zeta-functions of Laplacians {\footnote{ For this, see \cite{W} and its bibliography, which {\it remains} a useful, and delightful,   thing to read!}}. As for the Gibbs phenomenon, Theorem 3 of \cite{Fu3} offers the following jump-discontinuity analysis (in the variable $X$) for the analytic continuation of the Dirichlet series $Z_{\rm Riemann}(X,s)$ at real points $0 < s = \sigma < 1$.

 $$\lim_{X \to p^k\pm 0}{{Z_{\rm Riemann}(X,\sigma)}{|\log X -\log(p^k)|^{1-\sigma}} \ = \ \mp {\frac{\log p}{2\pi p^{k/2}}}\int_0^{\infty}{\frac \sin t}{t^{\sigma}}}dt.$$
 \vskip10pt
 \begin{project} Rework this theory to cover the case of $S_E(X)$.\end{project}
  \vskip10pt
  Here is a small picture exhibition of the Gibbs phenomenon for our oscillatory terms $S_E(X)$.  It is striking how roughly linear these oscillatory term appear, around---of course---the discrete jumps at powers of prime numbers.
 \vskip10pt

 \centerline{ $E = 11a$  between $40$ and $60$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/11a40t60.pdf}
    \newpage
  \centerline{ $E = 11a$  between $60$ and $100$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/11a60t100.pdf}

   \vskip10pt
   \centerline{ $E = 11a$  between $990$ and $1010$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/11a990t1010.pdf}

 \newpage
   \centerline{ $E = 37a$  between $40$ and $60$}

   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/37a40t60.pdf}

   \centerline{ $E = 37a$  between $60$ and $100$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/37a60t100.pdf}
 \newpage
  \centerline{ $E = 37a$  between $990$ and $1010$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/37a990t1010.pdf}
 \newpage
  \centerline{ $E = 389a$  between $40$ and $60$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/389a40t60.pdf}

   \centerline{ $E = 389a$  between $60$ and $100$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/389a60t100.pdf}
\newpage
  \centerline{ $E = 5077a$  between $40$ and $60$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/5077a40t60.pdf}

   \centerline{ $E = 5077a$  between $60$ and $100$}
   \vskip10pt
 \hskip100pt \includegraphics[width=0.6\textwidth]{plots/507760t100.pdf}


  \section{ To summarize:}  The  Explicit Formula for the `well-done data,' i.e., ${D}_E(X)$,  is then (conjecturally)
   $${D}_E(X)\ = \ -r+E \ +\ O( {\frac{1}{\log X}})\  +\  {\frac{1}{\log X}}S_E(X),$$
   where the rapidity of the conjectured convergence of ${D}_E(X)$ to $-r$ depends on a concrete understanding of the $O( {\frac{1}{\log X}})$ term, plus whether, and how rapidly, we expect  $S_E(X)$ to decrease. Putting it somewhat archly, one measure of the ease of application of  the Explicit Formula, or its 'explicitness,' is how large a value of $X$ do  you need for the following to be a true equation:

   $$r_E \ = \ {\rm the\ closest\ integer\ to \ }- {D}_E(X)?$$


   \vskip40pt
 \centerline{ \Large{ Part II: Some  theory}}
  \vskip30pt


    \section{The letter of Peter Sarnak}  In a letter  \cite{S}  to one of us (to B.M.) Peter Sarnak sketched reasons for the statements made about the three formats for sums of local data that we  introduced above. As we  understand it, the computations in that letter was, at least in part, the fruit of conversations with Andrew Granville and also an outgrowth of \cite{R-S}. We are grateful for that letter, and for  illuminating discussions with    Granville, Rubinstein, and Sarnak.  Assuming a list of standard conjectures about the behavior of $L$-functions, together with some very plausible but less standard conjectures, Sarnak begins by showing---as we mentioned above---that (conditional on standard conjectures) the medium-rare local data,  ${\mathcal D}_E(X)$, has a limiting distribution with {\it mean} equal to $1- 2r_E$.

  The {\it variance} of this limiting distribution  is the sum of the squares of the reciprocals of the absolute values of the nonreal zeroes of the $L$-function of $E$. The argument for these (and related) facts follows Mike Rubenstein's and Peter Sarnak's line of reasoning in the article {\it Chebyshev's Bias} [\ref{R-S}]. For another expository account of number theoretic issues related to biases, see [\ref{GM}]. Similar reasoning works for other formats, including the {\it raw} sum of local data as will be depicted in our graphs below; i.e.,  $$\Delta_E(X):= {\frac{\log\ X}{\sqrt X}}\big(\#\{ {p \le X};\ a_E(p) > 0\} \ - \ \#\{ {p \le X};\ a_E(p) < 0\}\big),$$ which  (given reasonable conjectures, and guesses)  one discovers to have infinite {\it variance} so whatever bias we will be seeing in our finite stretch of data will eventually wash out{\footnote{ All this is specific to elliptic curves $E$ with no complex multiplication, as our examples below all are. The non-finiteness of the variance is related to the fact that the (expected) number of  zeroes---in  intervals  $(1/2, i/2+iT)$ ($T > 0$)---of the $L$ function of the $n$-th symmetric power of the newform $f_E$ attached to  $E$   grows at least linearly with $n$.}}.





%  Let $E$ be an elliptic curve over the field of rational numbers, and for all primes $p$ for which the reduction of $E$ modulo $p$ is an elliptic curve over the prime field ${\bf F}_p$  (this will happen for all but finitely many $p$) let $N_E(p):= |E({\bf F}_p)|$  be the number of points of the reduction of $E$ over ${\bf F}_p$.  To more easily compare $N_E(p)$ with the quantity $p+1$, put $a_E(p):= (p+1)-N_E(p)$ so that our estimate ($p+1$) is an ``over-count"  for the number of points of our elliptic curve $E$ mod $p$  if and only if  $a_E(p)$ is positive; and an ``under-count" if negative.

% In a letter  [\cite{S}]  to one of us (to B.M.) Peter Sarnak sketched reasons for the statements made about the three formats for sums of local data that we  discussed in Part I above. As we  understand it, the computations in that letter was, at least in part, the fruit of conversations with Andrew Granville. We are grateful for that, and for  illuminating discussions with    Granville, Rubinstein, and Sarnak about this  phenomenon.  As already mentioned, assuming a list of standard conjectures about the behavior of $L$-functions, together with some very plausible but less standard conjectures, Sarnak begins by showing that $$X\mapsto {\frac{\log\ X}{\sqrt X}}\sum_{p \le X}{\frac{a_E(p)}{\sqrt p}}$$ has a limiting distribution with {\it mean} equal to $1- 2r(E)$ where $r(E)$ is the Mordell-Weil rank of the elliptic curve $E$.

 % The {\it variance} of this limiting distribution  is the sum of the squares of the reciprocals of the absolute values of the nonreal zeroes of the $L$-function of $E$. The argument for this follows Mike Rubenstein's and Peter Sarnak's line of reasoning in the article {\it Chebyshev's Bias} [\ref{R-S}]{\footnote{For another expository account of number theoretic issues related to biases, see [\ref{GM}].}}. If, however, we apply similar reasoning to the quantity specifically measuring the race depicted in our graphs; i.e.,  $$X\mapsto {\frac{\log\ X}{\sqrt X}}\big(\#\{ {p \le X};\ a_E(p) > 0\} \ - \ \#\{ {p \le X};\ a_E(p) < 0\}\big) $$ one computes  (given reasonable conjectures, and guesses) the {\it mean} and one discovers that it conforms fairly well with the data; the {\it variance}, however, is infinite, so whatever bias we see in our finite stretch of data will eventually wash out{\footnote{ This is specific to elliptic curves $E$ with no complex multiplication, as our examples below all are. The non-finiteness of the variance is related to the fact that the (expected) number of  zeroes---in  intervals  $(1/2, i/2+iT)$ ($T > 0$)---of the $L$ function of the $n$-th symmetric power of the newform $f_E$ attached to  $E$   grows at least linearly with $n$.}}.  In this section, and subsequent subsections, I will be simply transcribing---with minor notational modifications---a few extracts from a letter that Peter Sarnak wrote to me.

 \section{`Explicit Formula' statistics}

Let $E$ be an elliptic curve over ${\Q}$ without complex multiplication associated to a newform $f$ with Fourier expansion:
$$f(q) = q+\sum_{n\ge 2}a_E(n)q^n.$$

For $p$ a prime, write

\begin{equation}
{\frac{a_E(p)}{\sqrt p}}: = \   \alpha_p+\beta_p,
\end{equation}

with $\alpha_p= e^{i\theta_p}$ and  $\beta_p= e^{-i\theta_p}$
and
\begin{equation}
  \theta_p \in [0, \pi].
\end{equation}


Our basic data consists of the function

\begin{equation}\label{data}
p \ \mapsto\ \theta_p
\end{equation}

To have some vocabulary to deal with its statistics, consider

$$U_n(\theta) : = {\frac {\sin(n+1)\theta}{\sin\theta}}$$ and note that the set $\{U_n\}$ for $n=0,1,2,\dots$ forms an orthonormal basis of the Hilbert space $L^2[0,\phi]$.

For $V(\theta)$ a smooth function on $[0,\pi]$, write $V=\sum_{n=0}^{\infty} c_nU_n$ with $c_n: = \langle V, U_n\rangle$.

Just to cut down to the essence as rapidly as possible, and just for this lecture:

\begin{definition} Say that our data (\ref{data}) has {\bf `Explicit Formula' statistics} if there is a sequence of non-negative integers $\{r_n\}_n$  for $n=1,2,3, \dots$ such that for all smooth functions $V(\theta)$ as above with $c_0=0$, the ``$V$-weighted average of the data"
\begin{equation}
S_V(X):= {\frac{\log X}{\sqrt X}}\sum_{p \le X} \ V(\theta_p)
\end{equation}
\begin{itemize}
\item
possesses a limiting distribution{\footnote{ Recall that, as in subsection    \ref{statdist} above,  $S_V(x)$ {\bf possesses a limiting distribution $\mu_V$ with respect to the multiplicative measure $dx/x$} if for continuous bounded functions $f$ on ${\bf R}$ we have:
\begin{equation}
\lim_{X \to {\infty}}\ {\frac{1}{\log X}}\int_0^Xf(S_V(x))dx/x \ = \ \int_{\bf R}f(x)d\mu_V(x).
\end{equation}}}
 $\mu_V$ with respect to the multiplicative measure $dX/X$,
\item  $\mu_V$ has support on all of ${\bf R}$ is continuous and symmetric about its mean, ${\mathcal E}(S_V)$, and
\begin{equation}\label{eqnmean}
{\mathcal E}(S_V)\ = \ -\sum_{n=1}^{\infty}  c_n\big(2r_n+(-1)^n\big).
\end{equation}
\end{itemize}
\end{definition}

\bigskip
One can also compute---given some plausible conjectures---the behavior of the {\bf variance}  (i.e., the measure of fluctuation of the values of $S_V(X)$ about the mean) as well; the variance is defined by the formula  $${\mathcal V}(S_V): = {\mathcal E}\big([S_V  - {\mathcal E}(S_V)]^2\big).$$


\begin{remark}  If some standard conjectures{\footnote{that (for $n=1,2,\dots$) the $L$-functions of the symmetric $n$-th powers of the elliptic curve, \begin{equation}
L(s, E, {\rm sym}^n): = \prod_p\prod_{j=0}^n(1- \alpha_p^{n-j}\beta_p,^jp^{-s})^{-1},
\end{equation} have analytic continuation   to the entire complex plane satisfying a standard function equation (and one can relax analyticity and require merely an appropriate meromorphicity hypothesis) and that they be holomorphic and nonvanishing up to $Re(s) =1/2$ (i.e., GRH).  The integer $r_n$ (for $n=1,2,\dots$)  is then the multiplicity of the zero of $L(s, E, {\rm sym}^n)$ as $s=1/2$. \vskip20pt }} and some non-standard conjectures{\footnote{LI(E); see  \ref{S}, \ref{F}}}  hold, then our data (\ref{data}) would indeed have {\it `Explicit Formula' statistics}; for details, see \cite{S}.  The integers $r_n$, which by the previous footnote are (conjecturally) the orders of vanishing of specific $L$-functions at their central points, are expected to have the large preponderance of their values equal to  $0$ or $1$, depending on the sign of the functional equation satisfied by the $L$-function to which they are associated,  so the {\it mean} for  a given $V$ as computed by equation (\ref{eqnmean}) stands a good chance of being finite.
\end{remark}


\section{The bias between under-counts and over-counts}
  We will assume that our data has `Explicit Formula' statistics, and---copying Sarnak ({\cite{S}})--- apply this to the question we began with, i.e., what is the ``bias" in the race between under-counts and over-counts?

$$\Delta_E(X):={\frac{\log X}{\sqrt X}}\big(\#\{ p < X\ | \ N_E(p) < p+1\}\ - \ \#\{ p < X\ | \ N_E(p) > p+1\}\big).$$


Let $H(\theta)$ be the Heaviside function, i.e., the function with value

\begin{equation}
H(\theta) \ = \ +1
\end{equation}
 for $\theta \in [0, \pi/2)$ and  $-1$ for $\theta \in [\pi/2, \pi)$.  So
\begin{equation}
\Delta_E(X) = {\frac{\log X}{\sqrt X}}\sum_{p\le X} H(\theta_p)
\end{equation}


For $n \ge 0$, set


\begin{equation}
c_n(H)  \ = \ \langle H, U_n\rangle \ = \ {\frac{2}{\pi}}\big[\int_0^{\pi/2}U_n\sin^2\theta d \theta - \int_{\pi/2}^{\pi}U_n\sin^2\theta d \theta \big]
\end{equation}


which is $0$ if $n$ is even and $$(-1)^{(n-1)/2}{\frac{2}{\pi}}\big[{\frac{1}{n}} + {\frac{1}{n+2}}\big]$$ if $n$ is odd.



For $N \ge 1$ let

\begin{equation}
H_N(\theta): = \ \sum_{n=1}^Nc_n(H)U_n(\theta)
\end{equation}


So $H_N$ is a smoothed out version of $H(\theta)$ and $H_N(\theta) \to H(\theta)$ as $N $ tends to infinity.  Thus

\begin{equation}
S_N(X): = S_{H_N}(X) = \ {\frac{\log X}{{\sqrt{X}}}}\sum_{p \le X}H_N(\theta_p)
\end{equation}


is a smoothed out version of

\begin{equation}\label{smooth}
S(X): = S_{H}(X) = \ {\frac{\log X}{{\sqrt{X}}}}\sum_{p \le X}H(\theta_p)
\end{equation}

Therefore, by formula (\ref{eqnmean}), we would have:

\begin{equation}\label{early}
{\mathcal E}(S_N)\ = \ {\frac{8}{3\pi}}(1-2r) + {\frac{2}{\pi}} \sum_{k=1}^{N}  (-1)^{k+1}\big[{\frac{1}{2k+1}} + {\frac{1}{2k+3}}\big]\big(2r_E(2k+1)-1\big).
\end{equation}


Now one does have  parity information concerning the arithmetic function $n \mapsto r_E(n)$. For a detailed study of the root numbers of $L$-functions of symmetric powers of an elliptic curve, consult \cite{DMW}.
 For $n \ge 1$ let $ \nu_E(n) \in \{0,1\}$ be (zero or one) such that  $ \nu_E(n) \equiv r_E(n)$ modulo $2$. Let $s_E(n)$ be the non-negative integer such that:
 $$r_E(n) = \nu_E(n) + 2s_E(n)$$  (for $n\ge 3$, odd).
Thus if the multiplicity of order of vanishing at the central point $s=1/2$ of the odd symmetric $n$-th power $L$-functions attached to $E$ (for $n \ge 3)$ were never greater than  $1$, and hence entirely dictated by parity, then the conjectured mean, ${\mathcal E}(S_N)$, would be equal to
\begin{equation}\label{min}
{\mathcal T}_E^{\{N\}}\ := \ {\frac{8}{3\pi}}(1-2r_E) + {\frac{2}{\pi}} \sum_{k=1}^{N}  (-1)^{k+1}\big[{\frac{1}{2k+1}} + {\frac{1}{2k+3}}\big]\big(2\nu_E(2k+1)-1\big).
\end{equation}

  Now consider the limit:
   $${\mathcal T}_E: = \lim_{N\to \infty}{\mathcal T}_E^{\{N\}}. $$
\vskip20pt
\begin{project} Check if all the possibilities for parity as given in \cite{DMW} leads, in fact, to convergent values of ${\mathcal T}_E$.  Work out those values. E.g., In \cite{DMW} one reads that for $n$ odd and $E$ semistable, the parities of $symm^nE$ are all the same;  i.e., independent of (odd) $n$. So in the semistable case, $${\mathcal T}_E = {\frac{8\pm 2}{3\pi}} -{\frac{16}{3\pi}}r_E,$$ where the sign depends on whether  $\nu_E(2k+1)$ is $1$ or $0$.\end{project}
\vskip20pt


Put $${\z}_E^{\{N\}}:= {\frac{2}{\pi}}\sum_{k=1}^{N}  (-1)^{k+1}\big[{\frac{1}{2k+1}} + {\frac{1}{2k+3}}\big]\big(4s_E(2k+1)\big).$$

\vskip20pt
\noindent {\bf Questions:} Does the limit, $${\z}_E: = \lim_{N\to \infty}{\z}_E^{\{N\}} $$  exist? Does it converge to a finite value?  If so, then the conjectured mean would be:
$${\mathcal E}_E =  {\mathcal T}_E \ + \ \z_E.$$   Is $s_{2k+1}$ bounded?  Is  the set of positive integers $k$ such that  $s_{2k+1} \ne 0$ of {\it density zero} set of positive integers $k$?    Is that set finite?



 Some data for higher order of vanishing for symmetric powers is given in the article of Martin and Watkins \cite{M-W}. The following table is taken from their article:


\hskip160pt\begin{tabular} {l | r r}\hline
$E$ & $k$ & $s_{2k+1}$\\
\hline\hline
$2379b$ & 1 & 2 \\
\hline
$5423a$ &  1 & 2   \\
\hline
$10336d$ &  1 & 2  \\
\hline
$29862s$ &  1 & 2  \\
\hline
$816b$ &  2 & 1  \\
\hline
$2340i$ &  2 & 1  \\
\hline
$2432d$ &  2 & 1  \\
\hline
$3776h$ &  2 & 1  \\
\hline
$128b$ &  3 & 1  \\
\hline
$160a$ &  3 & 1  \\
\hline
$192a$ & 3 & 1  \\
\hline
\end{tabular}

\vskip40pt


\vskip10pt
\section{The relationship between bias and unbounded rank: the work of Fiorilli}\label{Fi}

  Recall from Section {\ref{mean}} above that the {\bf mean} of $\delta(X)$ is by definition:
$${\mathcal E} : = \lim_{X \to {\infty}}\ {\frac{1}{\log X}}\int_0^X\delta(x)dx/x \ = \ \int_{\bf R}d\mu_\delta(x).$$
In the work of Sarnak and Fiorilli, another measure for understanding `bias behavior' is given by what one might call {\bf the percentage of positive  support} (relative to the multiplicative measure $dX/X$). Namely:
$${\mathcal P} ={\mathcal P}_E:=  \lim {\rm inf}_{X\to \infty}{\frac{1}{\log X}}\int_{2\le x \le X; \delta(x)\le 0}dx/x$$
$$=   \lim {\rm sup}_{X\to \infty}{\frac{1}{\log X}}\int_{2\le x \le X; \delta(x)\le 0}dx/x$$
 \vskip20pt

  It is indeed a conjecture, in specific instances interesting to us, that these limits ${\mathcal E} $ and ${\mathcal P}$  exist.
   \vskip20pt

   The standard conjecture (that we have been making all along) is GRH. But here, one includes the further conjecture (given in Sarnak's letter, and the article of Fiorilli) that the the set of nontrivial complex zeroes of the relevant $L$-function $L(E,s)$ with positive imaginary part  is a set of complex numbers that are {\it linearly independent} over ${\Q}$. Such a conjecture Rubenstein and Sarnak refer to in \cite{R-S} as the {\it Grand Simplicity Hypothesis} (GSH).  Fiorilli calls his version of it  {\it Hypothesis LI(E)}.  For recent, somewhat related, work on such linear independence questions, see \cite{M-N}.   Fiorilli, following the work of Sarnak,  proves:

   \begin{theorem} Assume GRH and LI(E). Then the following two statements are equivalent:
   \begin{enumerate} \item  The set of (analytic) ranks $\{r_E\}_E$ ranging over all elliptic curves over ${\Q}$ is {it unbounded}.
   \item  The  l.u.b of the set of  {\it percentages of positive support}  $\{{\mathcal P}_E\}_E$ is equal to $1$.\end{enumerate}\end{theorem}
\section{The relationship between bias and bounding the rank: the work of Bober}  In \cite{B}, Jonathan Bober  establishes a conditional upper bound on the ranks of various known elliptic curves of (relatively) high Mordell-Weil rank, notably Noam Elkies'  elliptic curve $E_{28}$ for which $28$ linearly independent rational points have been found; Bober shows, conditional on the Birch-Swinnerton-Dyer conjecture and GRH, that the Mordell-Weil rank of $E_{28}$ is either $28$ or $30$. He does this by a nice `bias' computation using the Explicit Formula.

\vskip10pt
\section{Further finer questions: conditional biases}
\vskip10pt
%\centerline{To be written}

 In summary, given the conjectures discussed, the {\it theory of the means} of the general weighted sums of local data we have been examining related to an elliptic curve $E$ is determined by the orders of vanishing at the central point of the $L$-functions of the symmetric powers of the modular eigenform attached to $E$: and conversely: knowledge of the means of all such weighted sums determines all those orders of vanishing.


 \vskip20pt $$\{{\rm Weighted\ biases}\} \ \ \ \leftrightarrow\ \ \  \{{\rm Central\ zeroes}\}$$


This leads to  various issues needing conjectures, and computations. What might we reasonably conjecture about:

 \begin{enumerate}\item  {\it the arithmetic function  $k \mapsto r_E(2k+1)$?}
 \begin{itemize} \item Is it unbounded?
 \item Is $r_E(2k+1)\ge 2$ for  only a set of values of $k$ of density $0$?
 \item  Is  $r_E(2k+1)\ge 2$ for all but finitely many $k$'s?  \end{itemize} \vskip20pt
 \item {\it  the collection of weighted biases that have finite mean?}\  I.e., for which weighted biases does Equation \ref{eqnmean} have a convergent RHS?

 \vskip20pt \item {\it the detailed statistical behavior of the function $S_E(X,Y)$?}

  \vskip20pt \item {\it an effective version of LI(E)?}\  I.e., can we put our fingers on an explicit  positive function $F(H,T)$ such that for every linear combination of the form $$\sum_{j=1}^{\nu} \lambda_j\gamma_j$$ with the $\lambda_j$ 's rational numbers of height $< H$ and the  $\gamma_j$ 's  positive imaginary parts $<T$ of the complex zeroes of the $L$ function $L(E,s)$, we have  an inequality of the form $$|\sum_{j=1}^{\nu} \lambda_j\gamma_j|  > F(H, T)?$$
 %More specifically, the {\it means}  directly interpretable as {\it biases}  determine   the orders of vanishing at the central point of the $L$-functions of the symmetric powers of odd order of the modular eigenform attached to $E$ and vice versa..

   \vskip20pt \item {\it conditional biases?}  For example, given two elliptic curves $E_1, E_2$ over ${\Q}$ (that are not isogenous), say that a prime $p$ is of type $(+,+)$ if both $a_{E_1}(p)$ and $a_{E_2}(p)$ are positive, of type  $(+,-)$ if  $a_{E_1}(p)$ is  positive and $a_{E_2}(p)$ negative, etc.

 Now  {\it race} the four types of primes against each other!  What is the ensuing statistics, and how much of the analytic number theory regarding zeroes of $L$ functions attached to  $$symm^m(f_{E_1})\otimes symm^n(f_{E_2})$$  do we need to compute biases, if  such biases exist? \end{enumerate}
\vskip10pt
\section{Appendix: an example of a very classical `explicit formula'}

Let $\l(x)$ be the {\it Von Mangoldt Lambda-function}. That is, $\l(x)$ is zero unless $x= p^k$ is a power of a prime---$(k \ge 1)$---in which case $\l(p^k) := \log p$. Consider  $$\psi_0(X): = {\frac{1}{2}}\l(X) + \sum_{n < X}\l(n).$$ Although one might argue whether or not  $\psi_0(X)$ fits into the mold of what we have been calling a `sum of local data,' it is certainly {\it not} one of our bias sums of local data, which has been our principal concern. Nevertheless, it will serve,   and will sit, appropriately normalized,  on the LHS of Theorem \ref{ef}, our example of an `explicit formula.'
Let $\rho= {\frac{1}{2}}+i\gamma$ run through the zeroes in the line $Re(s)= {\frac{1}{2}}$ of the Riemann zeta function. (For expedience, we assume RH here).

\begin{theorem}\label{ef}{\bf (Explicit Formula)} $${\frac{1}{X}}\cdot \psi_0(X) \ = \ 1 \ - \ \sum_{|\gamma| \le T}{\frac{X^{i\gamma}}{({\frac{1}{2}}+i\gamma){\sqrt X}}} \ + \ C(X,T)$$

where---following the format of explicit formulas discussed above---we view \begin{itemize} \item  the term on the LHS of the above equation as our `sum of local data'; \item  the first term on the {\rm RHS},---i.e.,  $1$---as the `{\it global term}' corresponding to the pole of $\zeta(s)$ at $s=1$ with residue $1$; it is the {\it mean} of the {\rm LHS}, our sum of local data; \item  the second term on the {\rm RHS}, $\sum_{|\gamma| \le T}{\frac{X^{i\gamma}}{({\frac{1}{2}}+i\gamma){\sqrt X}}}$ as  a cutoff at $T$ of  the `{\it oscillatory term}' while \item  the third term, $C(X,T)$ is a cutoff at $T$ and at $X$ of the `{\it easy\ error term}.'  It converges to zero if the limits are taken in the order $$\lim_{X\to \infty}\lim_{T\to \infty}C(X,T).$$ This $C(X,T)$ has the following shape:

$$C(X,T): = {\frac{-\log(2\pi)-\log(1-1/X^2)/2}{ X}} + \epsilon(X,T), $$ where:

$$\epsilon(X,T) \ <<\ {\frac{\log X}{X}}\cdot {\rm min}\big(1, {\frac{X}{T\langle X \rangle}}\big)\ + \ {\frac{\log^2(X T) }{T}}.$$\end{itemize}\end{theorem}

Here, $\langle X \rangle$ is the distance between $X$ and the nearest prime power, and with all this, the $<<$ would still need ``explicitation''---even if that word is non-standard.  This result  and its proof is given, for example, as Theorem 12.5 in \cite{MV}.

We should note in passing that there is, of course, a massive literature on this type of formula relating the zeroes of the Riemann zeta function and $\pi(X)$, and relating $\pi(X)$ to the zeroes{\footnote{ For that, see, for example, \cite{G}.}}, in all its variants.


\newpage
 \centerline{ \Large{ Part III: Some pictures of the LHS}}
  \vskip30pt


     \section{The well-done data: \  $ {D}_E(X)$}
   \vskip40pt

      \centerline{\bf (Graphs of \ \   $X\mapsto {D}_E(X) = {\frac{1}{\log\ X}}\sum_{p \le X}{\frac{a_E(p)\log p}{ p}}$) }
      \vskip40pt

    \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank0-4million.png}
  \centerline{\bf Rank $r=0$:\ \ \  ${\mathcal E}=$11A.}
   \vskip20pt
    \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank0-4million.png}
%  \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank0-4million.png}{0.8}~\label{s11}


 \vskip40pt


  \centerline{\bf Rank $r=1$:\ \ \  ${\mathcal E}=$37A.}


   \vskip20pt



     \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank1-4million.png}{1.2}~\label{s37}
%

   \newpage


  \centerline{\bf Rank $r=2$:\ \ \  ${\mathcal E}=$389A.}


  \vskip20pt




     \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank2-4million.png}{1.2}~\label{s389}


 \vskip20pt


  \centerline{\bf Rank $r=3$:\ \ \  ${\mathcal E}=$5077A.}


 \vskip20pt



     \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank3-4million.png}{0.9}~\label{s5077}


  \vskip10pt

  \centerline{\bf Rank $r=4$.}


  \vskip20pt


     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-rank4-4million.png}{0.9}~\label{sr4}

 \vskip40pt


  %\centerline{\bf Rank $r=5$.}


 %\vskip20pt


     % \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-rank5-4million.png}{1.2}~\label{sr5}
 \newpage

  \centerline{\bf Rank $r=6$.}


 \vskip20pt



     \includegraphics[width=0.9\textwidth]{plots/even_smoother-rank6-4million.png}{1.2}~\label{sr6}
         \section{The medium-rare data:\   ${\mathcal D}_E(X)$}
       \vskip40pt

       \centerline{\bf (Graphs of \ \   $X\mapsto {\mathcal D}_E(X) = {\frac{\log\ X}{\sqrt X}}\sum_{p \le X}{\frac{a_{\mathcal E}(p)}{\sqrt p}}$)}

 \vskip40pt


  \centerline{\bf Rank $r=0$:\ \ \  ${\mathcal E}=$11A.}
   \vskip20pt
   \includegraphics[width=0.9\textwidth]{plots/illustsmooth-11}{.8}~\label{s11}
  \

    \newpage

  \centerline{\bf Rank $r=1$:\ \ \  ${\mathcal E}=$37A.}


   \vskip40pt



     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-37a-4million.png}{1.2}~\label{s37}
%

   \vskip40pt


  \centerline{\bf Rank $r=2$:\ \ \  ${\mathcal E}=$389A.}


  \vskip20pt


     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-389a-4million.png}{0.9}~\label{s389}


\newpage

\
  \centerline{\bf Rank $r=3$:\ \ \  ${\mathcal E}=$5077A.}


 \vskip10pt



     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-5077a-4million}{0.9}~\label{s5077}

  \vskip30pt


  \centerline{\bf Rank $r=4$.}


  \vskip10pt



     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-rank4-4million.png}{0.9}~\label{sr4}

 \newpage


  \centerline{\bf Rank $r=5$.}


     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-rank5-4million.png}{0.9}~\label{sr5}


  \vskip30pt


  \centerline{\bf Rank $r=6$.}


 \vskip20pt



     \includegraphics[width=0.9\textwidth]{plots/smooth-prime_race-rank6-4million.png}{1.2}~\label{sr6}
      \newpage
\section{The raw data: $\Delta_E(X)$}
\vskip40pt

  \centerline{\bf (Graphs of \ \   $X\mapsto \Delta_E(X)=  {\frac{\log\ X}{\sqrt X}}\#\{ p < X\ | \ a_E(p) > 0\}\ - \ \#\{ p < X\ | \  a_E(p) < 0\})$}  \vskip40pt


 \centerline{\bf Rank $r=0$:\ \ \  ${\mathcal E}=$11A.}~ \includegraphics[width=0.9\textwidth]{plots/normalized_straight-prime_race-11a-4million.png}{.8}~\label{nr11}


\vskip40pt



  \centerline{\bf Rank $r=1$:\ \ \  ${\mathcal E}=$37A.}


 \vskip60pt



     \includegraphics[width=0.9\textwidth]{plots/normalized_straight-prime_race-37a-4million.png}{.8}~\label{nr37}
%

  \vskip40pt



  \centerline{\bf Rank $r=2$:\ \ \  ${\mathcal E}=$389A.}


  \vskip20pt



     \includegraphics[width=0.9\textwidth]{plots/normalized_straight-prime_race-389a-4million.png}{.8}~\label{nr389}


   \vskip60pt


  \centerline{\bf Rank $r=3$:\ \ \  ${\mathcal E}=$5077A.}




     \includegraphics[width=0.9\textwidth]{plots/normalized_straight-prime_race-5077a-4million.png}{.8}~\label{nr389}







\begin{thebibliography}{bib}
 \bibitem{B}\label{B} Bober, J.W.: Conditionally bounding ranks of elliptic curves, (ar?iv:1112.1503)
 \bibitem{C-S}\label{C-S} Conrey, J.B., Snaith, N.C.:  On the orthogonal symmetry of $L$-functions of powers of a Hecke character, arxiv.org/pdf/1212.2681


 \bibitem{DMW}\label{DMW} Dummigan N, Martin P, Watkins M.: Euler factors and local root numbers for symmetric powers of elliptic curves, Pure and Applied Mathematics, Quarterly, {\bf 5},  no. 4, 1311-1341  (2009)
  \bibitem{F}\label{F}  Fiorilli, D.: Elliptic curves of unbounded rank and Chebyshev's Bias, preprint (2012)
        \bibitem{Fu1}\label{Fu1} Fujii, A.:  Comment. Math. Univ. Sancti Pauli, {\bf 31}, 99-113 (1982)
        \bibitem{Fu2}\label{Fu2} Fujii, A.:  Comment. Math. Univ. Sancti Pauli, {\bf 32}, 229-248 (1983)
      \bibitem{Fu3}\label{Fu3} Fujii, A.: Zeroes, Eigenvalues and arithmetic, Proc. Japan Acad., {\bf 60} 22-25 (1984)
    \bibitem{Fu4}\label{Fu4} Fujii, A.: An additive problem of prime numbers, III, Proc. Japan Acad., {\bf 67} 278-283 (1991)
   \bibitem{G}\label{G} Guinand, A. P.: A summation formula in the theory of prime numbers, Proc. London Math. Soc., {bf 50}, 107-119 (1945)
 \bibitem{GM}\label{GM}  Granville, A., Martin, G.:  Prime number races,
American Mathematical Monthly {\bf 113} 1-33 (2006)
  \bibitem{MV}\label{MV} Montgomery, H.L, Vaughan, R.C.:   {\it Multiplicative Number Theory I: Classical Theory} (Cambridge Studies in Advanced Mathematics) Cambridge University (2007)
  \bibitem{R-S}\label{R-S}   Rubinstein, M., Sarnak, P.: Chebyshev's Bias,  Experimental  Mathematics {\bf 3}  (1994) 174-197.
    \bibitem{S}\label{S} Sarnak, P.: Letter to Barry Mazur on ``Chebyshev's bias" for $\tau(p)$, http://web.math.princeton.edu/sarnak/MazurLtrMay08.PDF  November (2007)
  \bibitem{M-N}\label{M-N} Martin, G., NG, N.: Nonzero values of Dirichlet $L$-functions in vertical arithmetic progressions,
    arXiv:1109.1788v2 [math.NT]  Aug (2012)

        \bibitem{M-W}\label{M-W} Martin, G., Watkins, M.:  Symmetric powers of elliptic curve $L$-functions, arxiv.org/pdf/math/0604095

     \bibitem{W}\label{W}  Weyl, H.:  Ramifications, old and new, of the eigenvalue problem,  Bull. Amer. Math. Soc. {\bf 56}, Number 2 115-139 (1950)
\end{thebibliography}

\end{document}

